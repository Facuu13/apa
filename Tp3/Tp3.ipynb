{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 3: Predicción de tormenta en base de Datos Meteorológicos usando modelo más avanzados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes\n",
    "\n",
    "- Andrioli, Facundo\n",
    "- Pérez, José"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado y Evaluación:\n",
    "\n",
    "Utilizaremos el mismo dataset que en el TP2, manteniendo el mismo conjunto de entrenamiento y de evaluación, así como \n",
    "las métricas de evaluación definidas anteriormente. Seleccionar uno de los siguientes clasificadores vistos en las \n",
    "clases 6 y 7:\n",
    "- SVC\n",
    "- Árbol de clasificación\n",
    "- Bosques aleatorios\n",
    "- CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Evalúe el modelo con las métricas definidas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8506941187505862\n",
      "F1-score: 0.7398598909208629\n",
      "Matriz de confusión del modelo:\n",
      "[[32056  1082]\n",
      " [ 5285  4221]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "import pickle\n",
    "\n",
    "# Cargamos los datos de entrenamiento y prueba guardados en TP2\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "# Entrenamos el modelo de Bosques Aleatorios\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train.values.ravel())  # ravel para convertir DataFrame a array 1D# Hacemos predicciones en el conjunto de prueba\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1score_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# Mostramos los resultadosprint(\"\\n--Modelo Bosques Aleatorios--\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(f\"F1-score: {f1score_rf}\")\n",
    "print(\"Matriz de confusión del modelo:\")\n",
    "print(conf_matrix_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo en formato pickle para futuras evaluaciones\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Discuta las fortalezas y debilidades del modelo elegido en el contexto específico de este problema.\n",
    "Se tiene la libertad de realizar búsqueda de hiperparámetros o utilizar los valores por defecto. En caso de usar SVC, se recomienda encarecidamente realizar una búsqueda de hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de Bosques Aleatorios ofrece una buena precisión (85.07%) y maneja bien la complejidad de los datos, destacándose en problemas con muchas variables. Su capacidad para reducir el sobreajuste al combinar múltiples árboles lo convierte en una opción robusta. Sin embargo, su principal debilidad es la predicción de la clase minoritaria, como se ve en los falsos negativos (5,285). Aunque es menos interpretable que modelos como la regresión logística, su rendimiento justifica su uso en escenarios complejos como la predicción de tormentas. Además, puede ser computacionalmente intensivo, lo que podría ser una limitación en aplicaciones con recursos limitados.\n",
    "Aparte se selecciono por su equilibrio entre rendimiento, robustez y facilidad de uso, lo que lo hace adecuado para este problema sin requerir una optimización intensiva de hiperparametro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Construya una tabla comparativa con los resultados de los diferentes modelos y el modelo base. ¿Cuál fue el mejor modelo y por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Resuma los hallazgos más relevantes obtenidos durante todo el proceso desde el TP1 al TP3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Guarde en formato pickle el mejor modelo, seleccionado según su criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

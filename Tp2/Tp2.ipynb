{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Predicción de tormenta en base de Datos Meteorológicos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes\n",
    "\n",
    "- Andrioli, Facundo\n",
    "- Pérez, José"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de Datos: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lea el dataset limpio que se guardó en el TP1 (punto 2 de conclusiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargamos el conjunto de datos\n",
    "file = 'weatherAUS_output.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Realice una codificación adecuada de variables categóricas si es necesario, utilizando técnicas como One-Hot \n",
    "Encoding según corresponda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
      "0     12.7     15.8       0.8          1.4       7.8           35.0   \n",
      "1      6.2     15.1       0.0          1.8       2.1           20.0   \n",
      "2      5.3     15.9       0.0          1.4       8.0           30.0   \n",
      "3     11.3     15.7       0.0          1.4       1.5           52.0   \n",
      "4      7.6     11.2      16.2          4.6       1.1           46.0   \n",
      "\n",
      "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  WindDir3pm_NNW  \\\n",
      "0          13.0          15.0         75.0         52.0  ...           False   \n",
      "1           2.0          11.0         81.0         56.0  ...           False   \n",
      "2           6.0          13.0         71.0         46.0  ...           False   \n",
      "3          15.0          22.0         62.0         62.0  ...            True   \n",
      "4          17.0          13.0         83.0         88.0  ...           False   \n",
      "\n",
      "   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n",
      "0          False         False          False           False           False   \n",
      "1          False         False          False           False           False   \n",
      "2          False         False          False           False           False   \n",
      "3          False         False          False           False           False   \n",
      "4          False         False          False           False           False   \n",
      "\n",
      "   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
      "0           True         False           False           False  \n",
      "1           True         False           False           False  \n",
      "2          False         False           False           False  \n",
      "3          False         False           False           False  \n",
      "4           True         False           False           False  \n",
      "\n",
      "[5 rows x 3547 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identificamos las columnas categóricas\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Aplicamos One-Hot Encoding a las columnas categóricas\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Mostramos las primeras filas del dataset transformado\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Separe el dataset en entrenamiento y prueba (70% entrenamiento, 30% prueba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de X_train: 352834092\n",
      "Valores de y_train: 99502\n",
      "Valores de X_test: 42644\n",
      "Valores de y_test: 42644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definimos las características (X) y el objetivo (y)\n",
    "X = df_encoded.drop('RainTomorrow', axis=1)\n",
    "y = df_encoded['RainTomorrow']\n",
    "\n",
    "# Separamos el dataset en entrenamiento (70%) y prueba (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Datos de train y de test\n",
    "print(\"Valores de X_train:\",X_train.size)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Valores de X_test:\",len(X_test))\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Normalice o estandarice los atributos numéricos para asegurar que todas las variables tengan la misma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
      "5426  -0.728788 -1.024421 -0.136110    -0.529909 -0.727728      -1.583889   \n",
      "75590  1.160302  0.576340 -0.277473    -0.529909 -1.276662       0.281685   \n",
      "9368   0.098664  1.250345 -0.277473     0.171888  1.111201       0.558067   \n",
      "73772 -0.822462 -0.813794 -0.277473    -0.529909 -1.276662       0.212590   \n",
      "3398   0.286012 -0.855920 -0.230352    -0.572442 -1.249215      -1.583889   \n",
      "\n",
      "       WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  \\\n",
      "5426      -1.572602      2.009055     1.458635     0.935639  ...   \n",
      "75590      0.113636      0.794151     0.783584     1.270228  ...   \n",
      "9368      -0.336027      0.794151    -2.955154    -2.123465  ...   \n",
      "73772      0.563299      0.131476    -0.203027    -0.880704  ...   \n",
      "3398       1.575042      1.015042     0.523950     1.557019  ...   \n",
      "\n",
      "       WindDir3pm_NNW  WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  \\\n",
      "5426            False          False         False           True   \n",
      "75590           False          False         False          False   \n",
      "9368            False           True         False          False   \n",
      "73772           False          False         False          False   \n",
      "3398            False          False         False          False   \n",
      "\n",
      "       WindDir3pm_SSE  WindDir3pm_SSW  WindDir3pm_SW  WindDir3pm_W  \\\n",
      "5426            False           False          False         False   \n",
      "75590           False           False          False         False   \n",
      "9368            False           False          False         False   \n",
      "73772            True           False          False         False   \n",
      "3398            False           False          False         False   \n",
      "\n",
      "       WindDir3pm_WNW  WindDir3pm_WSW  \n",
      "5426            False           False  \n",
      "75590           False           False  \n",
      "9368            False           False  \n",
      "73772           False           False  \n",
      "3398            False           False  \n",
      "\n",
      "[5 rows x 3546 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identificamos las columnas numéricas\n",
    "numerical_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Creamos una instancia del StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustamos el escalador a los datos de entrenamiento y transformamos los datos de entrenamiento\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "\n",
    "# Utilizamos el mismo escalador para transformar los datos de prueba\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "# Mostramos las primeras filas del conjunto de entrenamiento transformado\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado y Evaluación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determine dos métricas de evaluación que considere importante medir para este problema. Justifique su elección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error cuadrático medio (MSE)\n",
    "\n",
    "El MSE mide la media de los cuadrados de los errores, es decir, la diferencia entre los valores predichos y los valores reales. Penaliza los errores grandes más severamente que los pequeños debido al cuadrado de los errores. Esto es útil cuando quieres evaluar la precisión de las predicciones y el impacto de errores grandes en el modelo.\n",
    "\n",
    "#### Raíz del error cuadrático medio (RMSE)\n",
    "\n",
    "El RMSE es la raíz cuadrada del MSE y proporciona una medida de la magnitud de los errores en las mismas unidades que la variable objetivo. Esto facilita la interpretación de los errores y la comparación con la escala de los datos. Es útil para evaluar el rendimiento del modelo de manera más intuitiva, ya que el RMSE tiene la misma unidad que las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implemente un modelo de base usando como predicción que determine que llueve mañana si hoy llueve, y si hoy no llueve\n",
    "mañana no va a llover. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo base: 0.7605759309633243\n",
      "Matriz de confusión:\n",
      "[[27997  5141]\n",
      " [ 5069  4437]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def base_model(rain_today):\n",
    "  return rain_today\n",
    "\n",
    "# Predecir con el modelo de base\n",
    "y_pred_base = base_model(X_test['RainToday'].astype(int)) \n",
    "\n",
    "# Evaluar el modelo de base\n",
    "accuracy = accuracy_score(y_test, y_pred_base)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_base)\n",
    "\n",
    "print(f\"Exactitud del modelo base: {accuracy}\")\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implemente y entrene un modelo de k Nearest Neighbors (kNN) para predecir si va a llover mañana. Utilice la \n",
    "distancia euclidiana como medida de distancia entre vecinos.Ajuste el parámetro k utilizando técnicas como la \n",
    "validación cruzada (5 folds) para optimizar el rendimiento del modelo (utilice como función de optimización una de las \n",
    "métricas definidas en el punto anterior). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Imputar los valores faltantes usando la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Definir el rango de valores para k\n",
    "param_grid = {'n_neighbors': list(range(1, 11))}\n",
    "\n",
    "# Crear el objeto KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Crear el objeto GridSearchCV con validación cruzada (5 folds) y la métrica de evaluación (Exactitud)\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Ajustar el GridSearchCV a los datos de entrenamiento\n",
    "grid_search.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Obtener el mejor valor de k\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "print(f\"Mejor valor de k: {best_k}\")\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_knn.predict(X_test_imputed)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Exactitud del modelo kNN con k={best_k}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implemente y entrene un modelo de regresión logística para predecir la misma variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evalúe los dos modelos con las métricas definidas al principio. Discuta las fortalezas y debilidades de cada enfoque \n",
    "en el contexto específico de este problema comparándolos con el modelo de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Resuma los hallazgos más relevantes obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Guarde los conjuntos de entrenamiento y evaluación para el siguiente TP en archivos `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Guarde en formato pickle el mejor modelo, seleccionado según su criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

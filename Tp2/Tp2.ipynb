{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Predicción de tormenta en base de Datos Meteorológicos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes\n",
    "\n",
    "- Andrioli, Facundo\n",
    "- Pérez, José"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de Datos: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lea el dataset limpio que se guardó en el TP1 (punto 2 de conclusiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargamos el conjunto de datos\n",
    "file = 'weatherAUS_output.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Realice una codificación adecuada de variables categóricas si es necesario, utilizando técnicas como One-Hot \n",
    "Encoding según corresponda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
      "0     12.7     15.8       0.8          1.4       7.8           35.0   \n",
      "1      6.2     15.1       0.0          1.8       2.1           20.0   \n",
      "2      5.3     15.9       0.0          1.4       8.0           30.0   \n",
      "3     11.3     15.7       0.0          1.4       1.5           52.0   \n",
      "4      7.6     11.2      16.2          4.6       1.1           46.0   \n",
      "\n",
      "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  WindDir3pm_NNW  \\\n",
      "0          13.0          15.0         75.0         52.0  ...           False   \n",
      "1           2.0          11.0         81.0         56.0  ...           False   \n",
      "2           6.0          13.0         71.0         46.0  ...           False   \n",
      "3          15.0          22.0         62.0         62.0  ...            True   \n",
      "4          17.0          13.0         83.0         88.0  ...           False   \n",
      "\n",
      "   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n",
      "0          False         False          False           False           False   \n",
      "1          False         False          False           False           False   \n",
      "2          False         False          False           False           False   \n",
      "3          False         False          False           False           False   \n",
      "4          False         False          False           False           False   \n",
      "\n",
      "   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
      "0           True         False           False           False  \n",
      "1           True         False           False           False  \n",
      "2          False         False           False           False  \n",
      "3          False         False           False           False  \n",
      "4           True         False           False           False  \n",
      "\n",
      "[5 rows x 3547 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identificamos las columnas categóricas\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Aplicamos One-Hot Encoding a las columnas categóricas\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Mostramos las primeras filas del dataset transformado\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Separe el dataset en entrenamiento y prueba (70% entrenamiento, 30% prueba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de X_train: 352834092\n",
      "Valores de y_train: 99502\n",
      "Valores de X_test: 42644\n",
      "Valores de y_test: 42644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definimos las características (X) y el objetivo (y)\n",
    "X = df_encoded.drop('RainTomorrow', axis=1)\n",
    "y = df_encoded['RainTomorrow']\n",
    "\n",
    "# Separamos el dataset en entrenamiento (70%) y prueba (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Datos de train y de test\n",
    "print(\"Valores de X_train:\",X_train.size)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Valores de X_test:\",len(X_test))\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Normalice o estandarice los atributos numéricos para asegurar que todas las variables tengan la misma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
      "5426  -0.728788 -1.024421 -0.136110    -0.529909 -0.727728      -1.583889   \n",
      "75590  1.160302  0.576340 -0.277473    -0.529909 -1.276662       0.281685   \n",
      "9368   0.098664  1.250345 -0.277473     0.171888  1.111201       0.558067   \n",
      "73772 -0.822462 -0.813794 -0.277473    -0.529909 -1.276662       0.212590   \n",
      "3398   0.286012 -0.855920 -0.230352    -0.572442 -1.249215      -1.583889   \n",
      "\n",
      "       WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  \\\n",
      "5426      -1.572602      2.009055     1.458635     0.935639  ...   \n",
      "75590      0.113636      0.794151     0.783584     1.270228  ...   \n",
      "9368      -0.336027      0.794151    -2.955154    -2.123465  ...   \n",
      "73772      0.563299      0.131476    -0.203027    -0.880704  ...   \n",
      "3398       1.575042      1.015042     0.523950     1.557019  ...   \n",
      "\n",
      "       WindDir3pm_NNW  WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  \\\n",
      "5426            False          False         False           True   \n",
      "75590           False          False         False          False   \n",
      "9368            False           True         False          False   \n",
      "73772           False          False         False          False   \n",
      "3398            False          False         False          False   \n",
      "\n",
      "       WindDir3pm_SSE  WindDir3pm_SSW  WindDir3pm_SW  WindDir3pm_W  \\\n",
      "5426            False           False          False         False   \n",
      "75590           False           False          False         False   \n",
      "9368            False           False          False         False   \n",
      "73772            True           False          False         False   \n",
      "3398            False           False          False         False   \n",
      "\n",
      "       WindDir3pm_WNW  WindDir3pm_WSW  \n",
      "5426            False           False  \n",
      "75590           False           False  \n",
      "9368            False           False  \n",
      "73772           False           False  \n",
      "3398            False           False  \n",
      "\n",
      "[5 rows x 3546 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identificamos las columnas numéricas\n",
    "numerical_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Creamos una instancia del StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustamos el escalador a los datos de entrenamiento y transformamos los datos de entrenamiento\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "\n",
    "# Utilizamos el mismo escalador para transformar los datos de prueba\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "# Mostramos las primeras filas del conjunto de entrenamiento transformado\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado y Evaluación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determine dos métricas de evaluación que considere importante medir para este problema. Justifique su elección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error cuadrático medio (MSE)\n",
    "\n",
    "El MSE mide la media de los cuadrados de los errores, es decir, la diferencia entre los valores predichos y los valores reales. Penaliza los errores grandes más severamente que los pequeños debido al cuadrado de los errores. Esto es útil cuando quieres evaluar la precisión de las predicciones y el impacto de errores grandes en el modelo.\n",
    "\n",
    "#### Error absoluto medio porcentual (MAPE)\n",
    "\n",
    "El MAPE mide el error absoluto en términos porcentuales respecto al valor real. Es decir, calcula el promedio de las diferencias absolutas entre los valores predichos y los valores reales, expresadas como un porcentaje del valor real. Esta métrica es útil porque ofrece una forma de evaluar la precisión del modelo en términos relativos, haciendo más fácil comparar el rendimiento del modelo entre diferentes escalas de datos o diferentes conjuntos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implemente un modelo de base usando como predicción que determine que llueve mañana si hoy llueve, y si hoy no llueve\n",
    "mañana no va a llover. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo base: 0.7605759309633243\n",
      "Matriz de confusión:\n",
      "[[27997  5141]\n",
      " [ 5069  4437]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def base_model_prediction(X):\n",
    "  return X['RainToday'].astype(int)\n",
    "\n",
    "# Predecir con el modelo de base\n",
    "y_pred_base = base_model_prediction(X_test) \n",
    "\n",
    "# Evaluar el modelo de base\n",
    "accuracy = accuracy_score(y_test, y_pred_base)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_base)\n",
    "\n",
    "print(f\"Exactitud del modelo base: {accuracy}\")\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implemente y entrene un modelo de k Nearest Neighbors (kNN) para predecir si va a llover mañana. Utilice la \n",
    "distancia euclidiana como medida de distancia entre vecinos.Ajuste el parámetro k utilizando técnicas como la \n",
    "validación cruzada (5 folds) para optimizar el rendimiento del modelo (utilice como función de optimización una de las \n",
    "métricas definidas en el punto anterior). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definiendo el clasificador kNN...\n",
      "Iniciando GridSearchCV para encontrar el mejor valor de k...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END ....................n_neighbors=1;, score=-0.196 total time= 4.7min\n",
      "[CV 2/5] END ....................n_neighbors=1;, score=-0.194 total time= 4.4min\n",
      "[CV 3/5] END ....................n_neighbors=1;, score=-0.198 total time= 4.4min\n",
      "[CV 4/5] END ....................n_neighbors=1;, score=-0.199 total time= 4.5min\n",
      "[CV 5/5] END ....................n_neighbors=1;, score=-0.198 total time= 4.4min\n",
      "[CV 1/5] END ....................n_neighbors=3;, score=-0.174 total time= 4.4min\n",
      "[CV 2/5] END ....................n_neighbors=3;, score=-0.168 total time= 4.4min\n",
      "[CV 3/5] END ....................n_neighbors=3;, score=-0.171 total time= 4.5min\n",
      "[CV 4/5] END ....................n_neighbors=3;, score=-0.172 total time= 4.3min\n",
      "[CV 5/5] END ....................n_neighbors=3;, score=-0.174 total time= 4.3min\n",
      "[CV 1/5] END ....................n_neighbors=5;, score=-0.165 total time= 4.6min\n",
      "[CV 2/5] END ....................n_neighbors=5;, score=-0.159 total time= 4.4min\n",
      "[CV 3/5] END ....................n_neighbors=5;, score=-0.161 total time= 4.5min\n",
      "[CV 4/5] END ....................n_neighbors=5;, score=-0.163 total time= 4.4min\n",
      "[CV 5/5] END ....................n_neighbors=5;, score=-0.167 total time= 4.6min\n",
      "[CV 1/5] END ....................n_neighbors=7;, score=-0.162 total time= 4.4min\n",
      "[CV 2/5] END ....................n_neighbors=7;, score=-0.158 total time= 4.4min\n",
      "[CV 3/5] END ....................n_neighbors=7;, score=-0.157 total time= 4.7min\n",
      "[CV 4/5] END ....................n_neighbors=7;, score=-0.160 total time= 4.5min\n",
      "[CV 5/5] END ....................n_neighbors=7;, score=-0.162 total time= 4.5min\n",
      "[CV 1/5] END ....................n_neighbors=9;, score=-0.160 total time= 4.5min\n",
      "[CV 2/5] END ....................n_neighbors=9;, score=-0.155 total time= 4.6min\n",
      "[CV 3/5] END ....................n_neighbors=9;, score=-0.157 total time= 4.4min\n",
      "[CV 4/5] END ....................n_neighbors=9;, score=-0.157 total time= 4.4min\n",
      "[CV 5/5] END ....................n_neighbors=9;, score=-0.160 total time= 4.6min\n",
      "[CV 1/5] END ...................n_neighbors=11;, score=-0.161 total time= 4.4min\n",
      "[CV 2/5] END ...................n_neighbors=11;, score=-0.153 total time= 4.4min\n",
      "[CV 3/5] END ...................n_neighbors=11;, score=-0.156 total time= 4.4min\n",
      "[CV 4/5] END ...................n_neighbors=11;, score=-0.155 total time= 4.5min\n",
      "[CV 5/5] END ...................n_neighbors=11;, score=-0.159 total time= 4.4min\n",
      "\n",
      "Mejor valor de k encontrado: 11\n",
      "Puntaje de validación cruzada (accuracy) con el mejor k: -0.16\n",
      "Entrenando el modelo kNN con el mejor valor de k...\n",
      "Modelo entrenado.\n",
      "Haciendo predicciones en el conjunto de prueba...\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.95      0.91     33138\n",
      "         1.0       0.74      0.48      0.58      9506\n",
      "\n",
      "    accuracy                           0.85     42644\n",
      "   macro avg       0.80      0.72      0.74     42644\n",
      "weighted avg       0.84      0.85      0.83     42644\n",
      "\n",
      "Exactitud del modelo: 0.8467545258418535\n",
      "Matriz de confusión del modelo:\n",
      "[[31568  1570]\n",
      " [ 4965  4541]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, classification_report\n",
    "\n",
    "# Creamos un imputador que reemplace los NaN por la media de cada columna\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Aplicamos el imputador a los datos de entrenamiento y prueba\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "print(\"Definiendo el clasificador kNN...\")\n",
    "knn = KNeighborsClassifier(metric='euclidean')\n",
    "\n",
    "# Definimos la métrica MSE para GridSearchCV\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Definimos los parámetros para GridSearchCV\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9, 11]}  # Probar valores de k impares\n",
    "print(\"Iniciando GridSearchCV para encontrar el mejor valor de k...\")\n",
    "\n",
    "# Usamos GridSearchCV para encontrar el mejor k usando validación cruzada (5 folds)\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring=mse_scorer, verbose=3)\n",
    "grid_search.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Mostramos el mejor parámetro k y el mejor puntaje\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"\\nMejor valor de k encontrado: {best_k}\")\n",
    "print(f\"Puntaje de validación cruzada (accuracy) con el mejor k: {best_score:.2f}\")\n",
    "\n",
    "# Entrenamos el modelo kNN con el mejor valor de k en el conjunto de entrenamiento\n",
    "print(\"Entrenando el modelo kNN con el mejor valor de k...\")\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k, metric='euclidean')\n",
    "best_knn.fit(X_train_imputed, y_train)\n",
    "print(\"Modelo entrenado.\")\n",
    "\n",
    "# Hacemos predicciones en el conjunto de prueba\n",
    "print(\"Haciendo predicciones en el conjunto de prueba...\")\n",
    "y_pred = best_knn.predict(X_test_imputed)\n",
    "\n",
    "# Evaluar el modelo\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(class_report)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(f\"Exactitud del modelo: {accuracy}\")\n",
    "print(\"Matriz de confusión del modelo:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implemente y entrene un modelo de regresión logística para predecir la misma variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo de regresión logística: 0.8505768689616359\n",
      "Matriz de confusión del modelo de regresión logística:\n",
      "[[31174  1964]\n",
      " [ 4408  5098]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Creamos una instancia del modelo de regresión logística\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento imputados\n",
    "log_reg.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_log_reg = log_reg.predict(X_test_imputed)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(f\"Exactitud del modelo de regresión logística: {accuracy_log_reg}\")\n",
    "print(\"Matriz de confusión del modelo de regresión logística:\")\n",
    "print(conf_matrix_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evalúe los dos modelos con las métricas definidas al principio. Discuta las fortalezas y debilidades de cada enfoque \n",
    "en el contexto específico de este problema comparándolos con el modelo de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Resuma los hallazgos más relevantes obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Guarde los conjuntos de entrenamiento y evaluación para el siguiente TP en archivos `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Guarde en formato pickle el mejor modelo, seleccionado según su criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
